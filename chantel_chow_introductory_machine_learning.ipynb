{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eea3c4d",
   "metadata": {},
   "source": [
    "# Recommendation of new mobile plan: Smart or Ultra \n",
    "\n",
    "Background:\n",
    "- We currently have a lot of subscribers using legacy mobile plan. \n",
    "\n",
    "Goal:\n",
    "- Our goal is to analyze subscribers' behavior and recommend them a new plan, Smart or Ultra.\n",
    "\n",
    "Stages:\n",
    "- We have already performed the data processing step earlier, so we will focus on creating the model here.\n",
    "\n",
    "- Since we are recommeding 2 plans, Smart or Ultra, we will use classification models as opposed to regression models. \n",
    "\n",
    "- We will set the threshold of accuracy to 0.75. We will split the data into training set, validation set and a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e35de1b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b></b> <a class=\"tocSkip\"></a>   \n",
    "    \n",
    "> # Contents <a id='back'></a>\n",
    "> * [Introduction](#intro)\n",
    "    * [Stage 1. Importing libraries](#Import-Libraries)\n",
    "    * [Stage 2. Load data](#Load-data)\n",
    "    * [Stage 3. Splitting data](#Splitting-data)\n",
    "    * [Stage 4. Testing different binary classifications](#Testing-different-binary-classification)\n",
    "        * [4.1 Logistic regression](#4.1-Logistic-regression)\n",
    "        * [4.2 Decision Tree Classifier](#4.2-Decision-Tree-Classifier )\n",
    "        * [4.3 Random Forest Classifierl](#4.3-Random-Forest-Classifier)\n",
    "    * [Stage 5. What model to choose ](#What-model-to-choose?)\n",
    "    * [Stage 6. Testing Logistic Regression on testing data](#Testing-Logistic-Regression-on-testing-data)\n",
    "    * [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b08c418",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c212d300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2dfe99",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03588050",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    subscribers = pd.read_csv('/Users/dankeichow/Downloads/users_behavior.csv')\n",
    "except:\n",
    "    subscribers = pd.read_csv('/datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef467a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "subscribers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d696dca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subscribers.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b618e7cd",
   "metadata": {},
   "source": [
    "We have already completed EDA in previous project and performed the following:\n",
    "\n",
    "* `removing duplicates`\n",
    "* Checking summary statistics with `describe()` function.\n",
    "* Various univariate and multi-variate visualisation you will learn in subsequent session.\n",
    "\n",
    "\n",
    "\n",
    "They are 3000+ rows of data. The number of calls, total call duration, number of text messages and MB used would be used as features. The is_ultra column (phone plan of the month) will be used as target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "612fb9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating seperate datasets to store features and target\n",
    "\n",
    "features = subscribers.drop(['is_ultra'], axis=1)\n",
    "\n",
    "target = subscribers['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343a93ae",
   "metadata": {},
   "source": [
    "# Splitting data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf99643",
   "metadata": {},
   "source": [
    "Since test set does not exist, the source data has to be split into 3 parts: train, validation and test sets. The size of validation set and test set are usually equal. \n",
    "\n",
    "Training data: 60%\n",
    "Validating data: 20%\n",
    "Test data: 20%\n",
    "\n",
    "We will have to set a specific random state value in order to ensure the reproducibility. We want to ensure that the splits remain the same even if the code is executed multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18bd329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train, validation and test sets\n",
    "\n",
    "# First step, splitting the data into a training set and a test set; 80% training and 20% test\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=12345 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "203660a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2056, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Second step, use the splitted 80% training data and split 20% out for validation set\n",
    "\n",
    "features_train, features_val, target_train, target_val = train_test_split(\n",
    "    features_train, target_train, test_size=0.2, random_state=12345 )\n",
    "\n",
    "features_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c96002e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data (2056, 4)\n",
      "shape of data (2056,)\n",
      "shape of data (515, 4)\n",
      "shape of data (515,)\n",
      "shape of data (643, 4)\n",
      "shape of data (643,)\n"
     ]
    }
   ],
   "source": [
    "test = [features_train, target_train,features_val,target_val,features_test,target_test]\n",
    "\n",
    "for shape in test:\n",
    "    test1 = shape.shape\n",
    "    print(f'shape of data {test1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b8bcf0",
   "metadata": {},
   "source": [
    "The datasets we have splitted now are:\n",
    "\n",
    "`training`: features_train, target_train\n",
    "\n",
    "`validation`: features_val, target_val\n",
    "\n",
    "`test`: features_test, target_test\n",
    "\n",
    "There are 1315 rows of data in our training set; 329 rows of data in our validation set, and 623 rows in our testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4c00e4",
   "metadata": {},
   "source": [
    "# Testing different binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944aac18",
   "metadata": {},
   "source": [
    "# 4.1 Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d95f27c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=12345, solver='liblinear')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st method: logistic regression \n",
    "# Imported above but just fyi: from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(random_state = 12345, solver='liblinear') #create an empty model\n",
    "lr_model.fit(features_train,target_train) #train the model with training data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44ba2010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 0.745136186770428\n",
      "Validation set accuracy: 0.7203883495145631\n"
     ]
    }
   ],
   "source": [
    "# Test the accuracy between training and validation\n",
    "\n",
    "# training data\n",
    "lr_train_predictions = lr_model.predict(features_train)\n",
    "lr_train_accuracy = accuracy_score(target_train, lr_train_predictions)\n",
    "\n",
    "# validation data\n",
    "lr_val_predictions = lr_model.predict(features_val)\n",
    "lr_val_accuracy = accuracy_score(target_val, lr_val_predictions)\n",
    "\n",
    "print(f'Training set accuracy: {lr_train_accuracy}')\n",
    "print(f'Validation set accuracy: {lr_val_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6f0c82",
   "metadata": {},
   "source": [
    "The logistic regression model correctly classified 74.5% of the data in the training set while 72% in the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc5af22",
   "metadata": {},
   "source": [
    "# 4.2 Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0721d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for max depth 1 for training is 0.7611867704280155.\n",
      "Accuracy for max depth 1 for validation is 0.7223300970873786.\n",
      "\n",
      "Accuracy for max depth 2 for training is 0.7923151750972762.\n",
      "Accuracy for max depth 2 for validation is 0.7475728155339806.\n",
      "\n",
      "Accuracy for max depth 3 for training is 0.811284046692607.\n",
      "Accuracy for max depth 3 for validation is 0.7553398058252427.\n",
      "\n",
      "Accuracy for max depth 4 for training is 0.8195525291828794.\n",
      "Accuracy for max depth 4 for validation is 0.7533980582524272.\n",
      "\n",
      "Accuracy for max depth 5 for training is 0.828307392996109.\n",
      "Accuracy for max depth 5 for validation is 0.7572815533980582.\n",
      "\n",
      "Accuracy for max depth 6 for training is 0.8336575875486382.\n",
      "Accuracy for max depth 6 for validation is 0.7611650485436893.\n",
      "\n",
      "Accuracy for max depth 7 for training is 0.8516536964980544.\n",
      "Accuracy for max depth 7 for validation is 0.7650485436893204.\n",
      "\n",
      "Accuracy for max depth 8 for training is 0.8706225680933852.\n",
      "Accuracy for max depth 8 for validation is 0.7631067961165049.\n",
      "\n",
      "Accuracy for max depth 9 for training is 0.8808365758754864.\n",
      "Accuracy for max depth 9 for validation is 0.7533980582524272.\n",
      "\n",
      "Accuracy for max depth 10 for training is 0.8939688715953308.\n",
      "Accuracy for max depth 10 for validation is 0.7592233009708738.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imported above but just fyi: from sklearn.tree import DecisionTreeClassifier \n",
    "# To check which max depth is more suitable and what is the accuracy for training and validation set\n",
    "\n",
    "\n",
    "for depth in range(1,11):\n",
    "    model = DecisionTreeClassifier(random_state = 12345, max_depth = depth)#create an empty model\n",
    "    model.fit (features_train, target_train)#train the model with training data\n",
    "    predictions_train = model.predict(features_train)\n",
    "    predictions_valid = model.predict(features_val) #get the model's prediction\n",
    "    accuracy_score_train=accuracy_score(target_train, predictions_train)\n",
    "    accuracy_score_val= accuracy_score(target_val, predictions_valid)\n",
    "    print(f'Accuracy for max depth {depth} for training is {accuracy_score_train}.')\n",
    "    print(f'Accuracy for max depth {depth} for validation is {accuracy_score_val}.')\n",
    "    print()      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b965e51",
   "metadata": {},
   "source": [
    "<b>Oberservation</b>\n",
    "\n",
    "Tested different max depth to see which max depth is most suitable to use. Here are the findings:\n",
    "- The accuracy for training set increases as the max depth increases \n",
    "- The accuracy for validation set decreases as the max depth increases \n",
    "\n",
    "If the accuracy for training is high but the validation accuracy is lower, this is a sign that the model is overfitting. Overfitting occurs when the model learns the training data too well and is not able to generalize the new data. \n",
    "\n",
    "Therefore, max depth 6 seems to be the best parameter for Decision tree classifier. The difference on accuracy score between training and validation is not too large so the model is not overfitting.\n",
    "\n",
    "Accuracy for max depth 6 for training is 0.8336575875486382\n",
    "\n",
    "Accuracy for max depth 6 for validation is 0.7611650485436893"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909e7917",
   "metadata": {},
   "source": [
    "# 4.3 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "128cce5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for n_estimators 1 for training is 0.9071011673151751.\n",
      "Accuracy for n_estimators 1 for validation is 0.7223300970873786.\n",
      "\n",
      "Accuracy for n_estimators 2 for training is 0.9051556420233463.\n",
      "Accuracy for n_estimators 2 for validation is 0.7398058252427184.\n",
      "\n",
      "Accuracy for n_estimators 3 for training is 0.9542801556420234.\n",
      "Accuracy for n_estimators 3 for validation is 0.7436893203883496.\n",
      "\n",
      "Accuracy for n_estimators 4 for training is 0.9460116731517509.\n",
      "Accuracy for n_estimators 4 for validation is 0.7533980582524272.\n",
      "\n",
      "Accuracy for n_estimators 5 for training is 0.9727626459143969.\n",
      "Accuracy for n_estimators 5 for validation is 0.7398058252427184.\n",
      "\n",
      "Accuracy for n_estimators 6 for training is 0.9640077821011673.\n",
      "Accuracy for n_estimators 6 for validation is 0.7553398058252427.\n",
      "\n",
      "Accuracy for n_estimators 7 for training is 0.9795719844357976.\n",
      "Accuracy for n_estimators 7 for validation is 0.7553398058252427.\n",
      "\n",
      "Accuracy for n_estimators 8 for training is 0.9747081712062257.\n",
      "Accuracy for n_estimators 8 for validation is 0.7669902912621359.\n",
      "\n",
      "Accuracy for n_estimators 9 for training is 0.9863813229571985.\n",
      "Accuracy for n_estimators 9 for validation is 0.7708737864077669.\n",
      "\n",
      "Accuracy for n_estimators 10 for training is 0.9800583657587548.\n",
      "Accuracy for n_estimators 10 for validation is 0.7650485436893204.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imported above but just fyi: from sklearn.ensemble import RandomForestClassifier\n",
    "# To check which n_estimator is more suitable and what is the accuracy for training and validation set\n",
    "\n",
    "best_score = 0\n",
    "best_est = 0\n",
    "\n",
    "for est in range(1,11):\n",
    "    model = RandomForestClassifier(random_state=12345, n_estimators = est) #create an empty model\n",
    "    model.fit(features_train,target_train) # training the model with training data\n",
    "    train_score = model.score(features_train, target_train)\n",
    "    val_score = model.score(features_val, target_val)\n",
    "    print(f'Accuracy for n_estimators {est} for training is {train_score}.')\n",
    "    print(f'Accuracy for n_estimators {est} for validation is {val_score}.')\n",
    "    print()     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dee4b9",
   "metadata": {},
   "source": [
    "<b> Oberservation </b>\n",
    "\n",
    "Tested different n_estimators to see which n_estimators is most suitable to use. Here are the findings:\n",
    "- The accuracy for training set increases as the max depth increases \n",
    "- The accuracy for validation set tend to increase but fluctuates as the max depth increases \n",
    "- Random Forest Classifier correctly classified at least 90% of the data in the training set\n",
    "\n",
    "There is overfitting issue with Random Forest Classifier. The accuracy score is too high and the difference between the training and validation data set are too wide.  \n",
    "\n",
    "The n_estimators = 2 is the best parameter as the difference between both training and validation dataset is smallest. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf898c9",
   "metadata": {},
   "source": [
    "# What model to choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeed6672",
   "metadata": {},
   "source": [
    "We have tested logistic regression, decision tree classifier and random forest classifer \n",
    "\n",
    "For classification metrics, we will have to decide if we value precision or recall. \n",
    "\n",
    "Recall will be a priority if it is important to find all required oberservations while precision will be important if the goal is to minimize the error. \n",
    "\n",
    "The project goal is to recommend newer plans to users. Therefore, accuracy seems to be less of a priority comparing to being able to recommend plan to all subscribers at Megaline. \n",
    "\n",
    "The random forest has too high accuracy which means model is overfitted so we will choose between logistic regression and decision tree classifier.\n",
    " \n",
    "Logistic regression has fastest run speed amongst the 3 models and has moderate accuracy amongst the 3. Even decision tree classifer has higher accuracy compares to logistic regression, the difference between the training data and validation set is wide which also suggests overfitting. \n",
    "\n",
    "The validation set accuracy between logistic regression and decision tree is about 3% apart. Therefore, I will pick logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2899e313",
   "metadata": {},
   "source": [
    "# Testing Logistic Regression on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "668a3485",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 0.745136186770428\n",
      "Validation set accuracy: 0.7203883495145631\n",
      "Test set accuracy: 0.749611197511664\n"
     ]
    }
   ],
   "source": [
    "# Already created empty model and trained data for regression model. Therefore, will not repeat\n",
    "\n",
    "#lr_model = LogisticRegression(random_state = 12345, solver='liblinear') \n",
    "\n",
    "#lr_model.fit(features_train,target_train) \n",
    "\n",
    "# Test the accuracy between on testing data\n",
    "lr_test_predictions = lr_model.predict(features_test)\n",
    "lr_test_accuracy = accuracy_score(target_test, lr_test_predictions)\n",
    "\n",
    "print(f'Training set accuracy: {lr_train_accuracy}')\n",
    "print(f'Validation set accuracy: {lr_val_accuracy}')\n",
    "print(f'Test set accuracy: {lr_test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba86ebe5",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da731bb7",
   "metadata": {},
   "source": [
    "The goal of the project is to recommend new mobile phone plans, Smart and Ultra, to exisiting subscribers. We are using behavior data from subscribers that have already switched to the new plans to recommend subscribers to pick a new plan.\n",
    "\n",
    "This is a classification task because we are not predicting numbers but category. We have tested logistic regression, random forest and decision tree. \n",
    "\n",
    "As we are trying to recommend to all users so the speed would be important and accuracy would be less of a priority. Therefore, I chose logistic regression as our machine learning model after comparing the 3. \n",
    "\n",
    "The result shows that the training set accuracy from logistic regression model correctly predicted 74.5% of the target. The validation set has lower accuracy of 72% while the testing set has higher accuracy than the validation set of 75%. \n",
    "\n",
    "The score between all 3 data sets are close which suggests the model is not overfitting and able to generalize to new data as well. \n",
    "\n",
    "The test score is higher than validation score suggests the model is able to learn the pattern in the data well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bed28b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
